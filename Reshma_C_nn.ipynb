{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z-nBw2pQwETV",
        "outputId": "48c1939e-e7a8-4215-fec0-e9628f9ccb12"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "#mount google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "import zipfile"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Problem statement:\n",
        "\n",
        "Build a CNN based model which can accurately detect melanoma. Melanoma is a type of cancer that can be deadly if not detected early. It accounts for 75% of skin cancer deaths. A solution which can evaluate images and alert the dermatologists about the presence of melanoma has the potential to reduce a lot of manual effort needed in diagnosis."
      ],
      "metadata": {
        "id": "btdKyAVNHFP9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "ZF412JCqWRai"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "\n",
        "# Update the path to point to the zip file within your Google Drive\n",
        "zip_ref = zipfile.ZipFile(\"/content/drive/My Drive/CNN_assignment.zip\") # Assuming the zip file is in your 'MyDrive' folder\n",
        "zip_ref.extractall(\"/tmp\")\n",
        "zip_ref.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "HEsbsJmdUgP5"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "with zipfile.ZipFile(\"/content/drive/My Drive/CNN_assignment.zip\",'r') as zip_ref:\n",
        "  zip_ref.extractall(\"/content/drive/MyDrive/Upgrad Case Study Loan Dataset/Melanoma Detection Assignment\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "sSgtbzpj-wj7"
      },
      "outputs": [],
      "source": [
        "#Importing all important libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "paCYqiBPwjOc"
      },
      "outputs": [],
      "source": [
        "import pathlib\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import PIL\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, Flatten, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint,EarlyStopping\n",
        "import pathlib\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import PIL\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint,EarlyStopping\n",
        "\n",
        "from tensorflow.keras.preprocessing.image import load_img\n",
        "import os\n",
        "data_dir = \"/content/drive/My Drive/CNN_assignment.zip/Skin cancer ISIC The International Skin Imaging Collaboration/Train\"\n",
        "print(data_dir)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "KiiKOZQtxNtw"
      },
      "outputs": [],
      "source": [
        "# Defining the path for train and test images\n",
        "data_dir_train = pathlib.Path('/content/drive/My Drive/Skin cancer ISIC The International Skin Imaging Collaboration/Train')\n",
        "data_dir_test = pathlib.Path('/content/drive/My Drive/Skin cancer ISIC The International Skin Imaging Collaboration/Test')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "g1mRNO2qdJkR"
      },
      "outputs": [],
      "source": [
        "# Count the number of image in Train and Test directory\n",
        "# Using the glob to retrieve files/pathnames matching a specified pattern.\n",
        "\n",
        "#Train Image count\n",
        "image_count_train = len(list(data_dir_train.glob('*/*.jpg')))\n",
        "print(image_count_train)\n",
        "\n",
        "#Test Image count\n",
        "image_count_test = len(list(data_dir_test.glob('*/*.jpg')))\n",
        "print(image_count_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New Section"
      ],
      "metadata": {
        "id": "x6u0c8zYEwka"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visualization of Data"
      ],
      "metadata": {
        "id": "RdorRKsuE5kr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "IfD_4aA2s4aS"
      },
      "outputs": [],
      "source": [
        "#Visualize one instance of all the class present in the dataset.\n",
        "\n",
        "#image_dataset_from_directory() will return a tf.data.Dataset that yields batches of images from the subdirectories.\n",
        "#label_mode is categorial, the labels are a float32 tensor of shape (batch_size, num_classes), representing a one-hot encoding of the class index.\n",
        "image_dataset = tf.keras.preprocessing.image_dataset_from_directory(data_dir_train,batch_size=32,image_size=(180,180),\n",
        "                                                                    label_mode='categorical',seed=123)\n",
        "\n",
        "#all the classes of Skin Cancer\n",
        "class_names = image_dataset.class_names\n",
        "\n",
        "#Dictionary to store the path of image as per the class\n",
        "files_path_dict = {}\n",
        "\n",
        "for c in class_names:\n",
        "    files_path_dict[c] = list(map(lambda x:str(data_dir_train)+'/'+c+'/'+x,os.listdir(str(data_dir_train)+'/'+c)))\n",
        "\n",
        "#Visualize image\n",
        "plt.figure(figsize=(15,15))\n",
        "index = 0\n",
        "for c in class_names:\n",
        "    path_list = files_path_dict[c][:1]\n",
        "    index += 1\n",
        "    plt.subplot(3,3,index)\n",
        "    plt.imshow(load_img(path_list[0],target_size=(180,180)))\n",
        "    plt.title(c)\n",
        "    plt.axis(\"off\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visualize distribution of classes in the training dataset.\n"
      ],
      "metadata": {
        "id": "ilvMDH67FKwe"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "iCvnvjvrs-zg"
      },
      "outputs": [],
      "source": [
        "#Visualize distribution of classes in the training dataset.\n",
        "def class_distribution_count(directory):\n",
        "\n",
        "    #count number of image in each classes\n",
        "    count= []\n",
        "    for path in pathlib.Path(directory).iterdir():\n",
        "        if path.is_dir():\n",
        "            count.append(len([name for name in os.listdir(path)\n",
        "                               if os.path.isfile(os.path.join(path, name))]))\n",
        "\n",
        "    #name of the classes\n",
        "    sub_directory = [name for name in os.listdir(directory)\n",
        "                    if os.path.isdir(os.path.join(directory, name))]\n",
        "\n",
        "    #return dataframe with image count and class.\n",
        "    return pd.DataFrame(list(zip(sub_directory,count)),columns =['Class', 'No. of Image'])\n",
        "\n",
        "df = class_distribution_count(data_dir_train)\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "4fVyLwCmtdbo"
      },
      "outputs": [],
      "source": [
        "#Visualize the Number of image in each class.\n",
        "import seaborn as sns\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.barplot(x=\"No. of Image\", y=\"Class\", data=df,\n",
        "            label=\"Class\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "hUis9jcitlLY"
      },
      "outputs": [],
      "source": [
        "#install Augmentor\n",
        "!pip install Augmentor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "6IMhPYLQuQWE"
      },
      "outputs": [],
      "source": [
        "path_to_training_dataset=\"/content/drive/My Drive/Skin cancer ISIC The International Skin Imaging Collaboration/Train/\"\n",
        "import Augmentor\n",
        "for i in class_names:\n",
        "    p = Augmentor.Pipeline(path_to_training_dataset + i)\n",
        "    p.rotate(probability=0.7, max_left_rotation=10, max_right_rotation=10)\n",
        "    p.sample(500)  #Adding 500 samples per class to make sure that none of the classes are sparse"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "lc0vCij5uYn2"
      },
      "outputs": [],
      "source": [
        "#Count total number of image generated by Augmentor.\n",
        "image_count_train = len(list(data_dir_train.glob('*/output/*.jpg')))\n",
        "print(image_count_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Building the model"
      ],
      "metadata": {
        "id": "FCs9YnrvFeMN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Wd5K4cOwuyNQ"
      },
      "outputs": [],
      "source": [
        "# train dataset\n",
        "train_ds = tf.keras.preprocessing.image_dataset_from_directory(data_dir_train, batch_size=32,\n",
        "                                                               image_size=(180,180), label_mode='categorical',\n",
        "                                                               seed=123,subset=\"training\",\n",
        "                                                               validation_split=0.2)\n",
        "\n",
        "#label_mode is categorial, the labels are a float32 tensor of shape (batch_size, num_classes),\n",
        "#representing a one-hot encoding of the class index."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "4u2WHdjRu4SA"
      },
      "outputs": [],
      "source": [
        "# validation dataset\n",
        "val_ds =tf.keras.preprocessing.image_dataset_from_directory(data_dir_train,batch_size=32,\n",
        "                                                            image_size=(180,180), label_mode='categorical',\n",
        "                                                            seed=123,subset=\"validation\",\n",
        "                                                            validation_split=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "hALJ5ubb2xHo"
      },
      "outputs": [],
      "source": [
        "#tf.data.experimental.AUTOTUNE defines appropriate number of processes that are free for working.\n",
        "\n",
        "#`Dataset.cache()` keeps the images in memory after they're loaded off disk during the first epoch.\n",
        "\n",
        "#`Dataset.prefetch()` overlaps data preprocessing and model execution while training.\n",
        "\n",
        "\n",
        "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
        "train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\n",
        "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "bY5wF0Re_BIg"
      },
      "outputs": [],
      "source": [
        "#Create the model\n",
        "#Todo: Create a CNN model, which can accurately detect 9 classes present in the dataset. Use layers.experimental.preprocessing.Rescaling to normalize pixel values between (0,1). The RGB channel values are in the [0, 255] range. This is not ideal for a neural network. Here, it is good to standardize values to be in the [0, 1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "wwXcl00125IJ"
      },
      "outputs": [],
      "source": [
        "#CNN Model Architecture\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "#Sequential allows you to create models layer-by-layer\n",
        "model = Sequential()\n",
        "\n",
        "#Rescaling Layer\n",
        "model.add(layers.Rescaling(1./255, input_shape=(180,180,3)))\n",
        "\n",
        "#First Convulation layer\n",
        "model.add(layers.Conv2D(32,kernel_size=(3,3),activation='relu'))\n",
        "model.add(layers.MaxPool2D(pool_size=(2,2)))\n",
        "\n",
        "#Second Convulation Layer\n",
        "model.add(layers.Conv2D(64,kernel_size=(3,3),activation='relu'))\n",
        "model.add(layers.MaxPool2D(pool_size=(2,2)))\n",
        "\n",
        "#Third Convulation Layer\n",
        "model.add(layers.Conv2D(128,kernel_size=(3,3),activation='relu'))\n",
        "model.add(layers.MaxPool2D(pool_size=(2,2)))\n",
        "\n",
        "#Dropout layer with 50% Fraction of the input units to drop.\n",
        "model.add(layers.Dropout(0.5))\n",
        "\n",
        "#Flatten Layer\n",
        "##Keras.layers.flatten function flattens the multi-dimensional input tensors into a single dimension.\n",
        "model.add(layers.Flatten())\n",
        "\n",
        "#Dense Layer\n",
        "model.add(layers.Dense(128,activation='relu'))\n",
        "\n",
        "#Dropout layer with 25% Fraction of the input units to drop.\n",
        "model.add(layers.Dropout(0.25))\n",
        "\n",
        "#Dense Layer with softmax activation function.\n",
        "#Softmax is an activation function that scales numbers/logits into probabilities.\n",
        "model.add(layers.Dense(len(class_names),activation='softmax'))\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "jdEmQZMD3PLO"
      },
      "outputs": [],
      "source": [
        "# visualizing the model\n",
        "from tensorflow.keras.utils import plot_model\n",
        "plot_model(model, to_file='model_plot.png', show_shapes=True, show_layer_names=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "1KEW-9wF4bs7"
      },
      "outputs": [],
      "source": [
        "#Compile the Model\n",
        "\n",
        "#Adam optimization: is a stochastic gradient descent method that is based on adaptive estimation of first-order and second-order moments.\n",
        "#categorical_crossentropy: Used as a loss function for multi-class classification model where there are two or more output labels.\n",
        "\n",
        "model.compile(optimizer=\"Adam\",loss=\"categorical_crossentropy\",metrics=[\"accuracy\"])\n",
        "\n",
        "#ModelCheckpoint callback is used in conjunction with training using model.fit() to save a model or weights (in a checkpoint file) at some interval,\n",
        "#so the model or weights can be loaded later to continue the training from the state saved.\n",
        "checkpoint = ModelCheckpoint(\"model.keras\",monitor=\"val_accuracy\",save_best_only=True,mode=\"auto\",verbose=1)\n",
        "\n",
        "#Stop training when a monitored metric has stopped improving.\n",
        "earlystop = EarlyStopping(monitor=\"val_accuracy\",patience=5,mode=\"auto\",verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "u_8KbVjjjsf1"
      },
      "outputs": [],
      "source": [
        "train_ds = train_ds.cache().prefetch(buffer_size=tf.data.AUTOTUNE)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vQ_a6DUwFzCc",
        "outputId": "cd13d474-a6b6-47e8-e910-a623add5e36e"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.17.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=3.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.11.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.64.1)\n",
            "Requirement already satisfied: tensorboard<2.18,>=2.17 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.17.0)\n",
            "Requirement already satisfied: keras>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.26.4)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.44.0)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (13.9.2)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.13.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2024.8.30)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.0.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "_F9wgFtq5Qnd"
      },
      "outputs": [],
      "source": [
        "# Train the model\n",
        "epochs = 20\n",
        "history = model.fit(train_ds, validation_data=val_ds, epochs=epochs,callbacks=[checkpoint,earlystop])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a8KlgsIcBFmW"
      },
      "outputs": [],
      "source": [
        "# Plot the training curves\n",
        "\n",
        "epochs_range = range(earlystop.stopped_epoch+1)\n",
        "\n",
        "plt.figure(figsize=(16, 6))\n",
        "plt.subplot(1, 2, 1)\n",
        "\n",
        "#Plot Model Accuracy\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel(epochs_range)\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "\n",
        "#Plot Model Loss\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel(epochs_range)\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4-4hxm9TGayB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model Prediction\n",
        "\n"
      ],
      "metadata": {
        "id": "qesfRaDQGkNB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from glob import glob\n",
        "Test_image_path = os.path.join(data_dir_test, class_names[1], '*')\n",
        "Test_image = glob(Test_image_path)\n",
        "Test_image = load_img(Test_image[0],target_size=(180,180,3))\n",
        "plt.imshow(Test_image)\n",
        "plt.grid(False)\n",
        "\n",
        "img = np.expand_dims(Test_image,axis=0)\n",
        "pred = model.predict(img)\n",
        "pred = np.argmax(pred)\n",
        "pred_class = class_names[pred]\n",
        "print(\"Actual Class     : \"+ class_names[1] +'\\n'+ \"Predictive Class : \"+pred_class )"
      ],
      "metadata": {
        "id": "-YIQI6o9GpIx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZmE5FVNpGsNF"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}